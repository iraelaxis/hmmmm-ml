# Основные задачи

TODO: краткое описание основных областей

* Классификация

* Регрессия



# Классификация задач по сложности

В оценке сложности указана минимальная граница. Т.е. сколько нужно потратить человеко-часов для создания PoC.




## NLP (обработка естественного языка)

Все нижеописанные области так или иначе опираются на наличие Text corpus по данным темам.

__Abstraction-based summarization.__ - суммаризация текста с перефразированием предложений. На данный момент технически нереализуема. Возможный подход - lstm, attention mechanism. (10\10)


__Extraction-based summarization.__ - суммаризация текста путём выдирания предложений без их изменений. (3\10)

Сама задача основана больше на применении статистических методик и применения готовых датасетов дистанции слов.
Суть текста может передаваться, а может и нет. Сам подход тупиковый по развитию. Реализуется относитально просто.


__Text classification.__ - классификация текста по темам (3-6\10)*

Зависит от наличия готовых датасетов. Минимально требуется от ~50000 слов по теме.



__Text clusterization.__ - кластеризация по темам (6/10)

Сложно оценивать качество модели.



__Information extraction.__ - извлечение информации из неформатированного текста (выделить автора, тему, создать структуру) (9/10)


__Sentiment analysis.__ - анализ общего настроения текста (2\10)

Сложность зависит от наличия языкового датасета положительного\отрицательного оттенка слова.



__Синонимайзеры, чат-боты, автоответчики по базе шаблонов__ (4\10)

ML подход лучше не использовать.





## Computer vision

Всё опирается на наличие датасета, для распознения требуется обычно ~10000 изображений по 
Сложность вычисляется исходя из предположения, что 10000 примеров присутствует в выборке.


###Image Recognition

__Определение есть ли [объект] на изображении.__ (2/10)

Вероятностная мера



__Определение если ли [объект №1]...[объект №2]...[объект №n] на изображении.__ (5/10)

В NN подходе могут быть проблемы при обучении сети (по сути - часть задачи классификации)



__Image Segmentation/Object detection.__ найти объект и выделить его границы (9/10)

Высокая сложность в силу проблемной подготовки датасета для обучения



#### Принцип создания DNN моделей\датасета в работе с изображениями:

__[Важные моменты]__

Любая сеть будет работать с изображениями размера максимум 64х64 (обычно 32х32). Если размер больше, то он ресайзится.
Следовательно объект, который необходимо распознать должен занимать собой минимум 70-80% изображения.

Если объект, который надо распознать, занимает ~50% места, то желательно трансформировать изображение так, чтобы он занимал 70-80, так как неизвестно, что из оставшихся 50% будет взято в качестве признаков этого объекта. Например весь датасет состоит из 1000 фотографий различных кошек с облаком в правом верхнем углу. Распознаётся фотография собаки с тем же облаком в правом верхнем углу. При распознании собака будет принята за кошку с 99% вероятностью, посколько последний связи в модели скорее всего будут выглядеть как: наличие массива белых пикселей(облако) -> кошка. Всё это относится к проблеме переобучения (overfitting) и разнообразия сэмплов см. проблемы.


Сложность задачи сегментации в том, что при создании датасета необходимо вручную создать маску формы (очертания) объекта для каждого изображения, либо найти готовый датасет с масками, а их не особо много.

__[Датасет]__

Датасет можно искусственно расширить, используя различные трансформаци (перемещение, увеличение\отдаление, повороты). Фильтры лучше не использовать.

При тренировке можно взять готовые веса, обнулив последний слой и дотренировав на какой-то конкретной задаче.


---

### Video


__Single object tracking.__ - трекинг одного объекта (8-9/10)


__Multi-object tracking.__ - трекинг множества объектов (9-10/10)

Включают в себя 3 задачи - сегментация объекта + идентификация объекта + множественное отслеживание.

Основные проблемы заключаются в установлении связи кадров друг с другом (тот же самый ли объект на кадре n-1 и кадре n), пересечении объектов друг с другом, идентификации неподвижных объектов, определении геометрии при подвижной камере.


__Определение действий объекта, т.е бег/драка/падение.__ (10/10)

Тема модная из-за теоретически допустимой возможности предотвращать преступления, автоматически анализируя видео с камер наблюдения. На данный момент технически нереализуема в прикладном плане (продакшн). Научным работам не верить.



### Time-series (временные ряды)
WIP
TODO: amr\features



### Задачи с прикладной регрессией (цифры итд)
WIP




# Усреднённое распределение времени при разработке

40% - выделение признаков (Feature extraction) и их формирование

20% - само построение модели

40% - тонкая настройка модели

Большинство времени тратится на подготовку данных к отправке в модель.




# Данные

## Признаки

Примерные пути создания признаков.

easy mode: найти признаки -> сформировать в csv таблицу -> отправить в pandas -> скормить модели

normal mode: Добавить отбор признаков (feature selection). Рассмотрение корреляций, вариаций
[NB] даже если признак обладает низкой значимостью (feature importance) выкидывать его может быть плохой идеей (см. проблема новых реальных данных)

hard mode: Генерация признаков. Рассмотрение статистических распределений, привод признаков к (как правило) нормальному распределению. Q–Q plot проверка. Полный перебор.




## Общий принцип подготовки датасета:

Деление данных на две части (train и test)
На train тренируется модель, на test - тестируется. Типичное соотношение - от 0.5\0.5 до 0.8\0.2


# Типичные проблемы

Проблема:
Новые реальные данные (не входящие в изначальную выборку) могут отличаться от исходных, модель их игнорирует.

Решение:
Самое простое - натренировать модель заного, включив в неё новые данные.
Сложнее - аккуратно понизить параметры модели (меньшее количество эпох для NN, ниже learning rate, e.t.c. Да, уменьшится точность, но модель будет охотнее принимать новые данные. Подробнее - уходить в проблему ovefitting. Суть решения - модель меньше основывается на некоторые специфический признаки для исходной выборки и смотрит больше в сторону более абстрактных.

---

Проблема:
Отсутствие некоторых данных (пропуски, N/A)

Решение:
В зависимости от типа модели заполнить пропуски либо средним значением, либо наименее вероятным значением для данных фич (если типичные значения в [-10, 10], то выставить -9999999999, 9999999999)

---





# Основные модели
WIP


# Проверка качества модели
WIP



# Доказательство качества модели
WIP



# Продвинутые модели (когда важны +/- 0.001% качества)
WIP

TODO: написать про ансамбли моделей